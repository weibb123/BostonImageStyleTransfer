# BostonImageStyleTransfer

##### Table of Contents  
[About](#About)
<a id="About"></a>\




[Content](#About)
This project uses pictures I took at Boston area and perform neural style transfer on them to create artwork.\
![picture1](https://user-images.githubusercontent.com/84426364/148293521-3e1e39ea-fa7b-44e6-bda2-efbc4c001f26.jpg)\
This picture is taken
![picture2](https://user-images.githubusercontent.com/84426364/148293524-201915e0-29ab-4ce4-8f1d-898cd5886e59.jpg)\
This picture is taken
![picture3](https://user-images.githubusercontent.com/84426364/148293528-2e69791d-17c5-40da-8956-39cf70dbe5e3.jpg)\
This picture is taken
![picture4](https://user-images.githubusercontent.com/84426364/148293529-3b69dbbe-5001-4a8a-9600-ee0d9aa82921.jpg)\
This picture is taken

The essential idea of neural style transfer is to define two distance function named d1 and d2\
d1 is responsible for describing how different the contenets of two images are.\
d2 is responsible for describing the difference between two images in terms of their style.\
Then, we take a content image and style image and transform content image by minimizing content and style distance with backpropagation










[Actknowledgement](#actknowledgement)
<a id="Actknowledgement"></a>
## Credit to https://www.linkedin.com/in/soumya044/ for his public notebook on Kaggle
and author https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf

https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398
